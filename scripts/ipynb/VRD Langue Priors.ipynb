{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of \"Visual Relationship Detection with Language Priors\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare data\n",
    "\n",
    "\n",
    "Our dataset (Table 1) contains 5000 images with 100 object categories and 70 predicates. In total, the dataset contains 37,993 relationships with 6,672 relationship types and 24.25 predicates per object category. Some example relationships are shown in Figure 3. The distribution of relationships in our dataset highlights the long tail of infrequent relationships (Figure 3 (left))\n",
    "\n",
    "\n",
    "#### TODO\n",
    "\n",
    "sample ~5000 images, compare statistics to these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: './GoogleNews-vectors-negative300.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fa72d3280ca7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./GoogleNews-vectors-negative300.bin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mword2vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/gensim/models/word2vec.pyc\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors)\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m             \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# throws for invalid file format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/smart_open/smart_open_lib.pyc\u001b[0m in \u001b[0;36msmart_open\u001b[0;34m(uri, mode, **kw)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;31m# local files -- both read & write supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;31m# compression, if any, is determined by the filename extension (.gz, .bz2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfile_smart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"s3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"s3n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# Get an S3 host. It is required for sigv4 operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/smart_open/smart_open_lib.pyc\u001b[0m in \u001b[0;36mfile_smart_open\u001b[0;34m(fname, mode)\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmake_closing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGzipFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: './GoogleNews-vectors-negative300.bin'"
     ]
    }
   ],
   "source": [
    "M = gensim.models.Word2Vec.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)\n",
    "word2vec = lambda t: M[t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Appearence Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1](eqs/1.png)\n",
    "\n",
    "where Θ is the parameter set of {zk , sk }. zk and sk are the parameters learnt to convert our CNN features to relationship likelihoods. k = 1, . . . , K represent the K predicates in our dataset. Pi (O1 ) and Pj (O2 ) are the CNN likelihoods of categorizing box O1 as object category i and box O2 as category j . CNN(O1 , O2 ) features extracted from the union of the O1 and O2 boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "O = # TODO: object probabilities: get final layer vector of \"probabilities\" from VGG-16 standard\n",
    "R = # TODO: get final layer of relationship CNN (use tensorflow . . .)\n",
    "def V(i, j, k, Z, S, O, R):\n",
    "    P_i = O[i]\n",
    "    P_j = O[j]\n",
    "    P_k = np.dot(Z[k].T, R[k]) + S[k]\n",
    "    return P_i * P_j * P_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![2](eqs/2.png)\n",
    "\n",
    "Next, we concatenate these two vectors together and transform it into the relationship vector space using a projection parameterized by W, which we learn. This projection presents how two objects interact with each other. We denote word2vec() as the function that converts a word to its 300 dim. vector. The relationship projection function (shown in Figure 4) is defined in Eq 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = # TODO: T['word'] = index\n",
    "\n",
    "def F(i, j, W, B, T):\n",
    "    \"\"\"\n",
    "    Project relationship `R = <i,j>` to K-dim relationship space.\n",
    "    \"\"\"\n",
    "    w2v = np.concatenate(word2vec(T[i]), word2vec(T[j]))\n",
    "    return np.dot(W.T, w2v) + B\n",
    "\n",
    "def f(i, j, k, W, B, T):\n",
    "    \"\"\"\n",
    "    Project relationship `R = <i,j>` to scalar space.\n",
    "    \"\"\"\n",
    "    w2v = np.concatenate(word2vec(T[i]), word2vec(T[j]))\n",
    "    return np.dot(W[k].T, w2v) + B[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Projection Function\n",
    "\n",
    "![3](eqs/3.png)\n",
    "\n",
    "where d(R, R′ ) is the sum of the cosine distances (in word2vec space [7])\n",
    "\n",
    "We want the distance between ⟨man - riding - horse⟩ to be close to ⟨man - riding - cow⟩ but farther from ⟨car - has - wheel⟩. We formulate this by using a heuristic where the distance between two relationships is proportional to the word2vec distance between its component objects and predicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Relationship:\n",
    "    def __init__(i, j, k):\n",
    "        self.r = (i,j,k)\n",
    "\n",
    "def dist(R1, R2, W, B, O, T):\n",
    "    d_rel = f(*R1.r, W, B, T) - f(*R2.r, W, B, T) \n",
    "    d_obj = M.similarity(M[R1.i], M[R1.j]) + \\\n",
    "            m.similarity(M[R2.i], M[R2.j])\n",
    "    return (d_rel ** 2) / d_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![4](eqs/4.png)\n",
    "\n",
    "To satisfy Eq 3, we randomly sample pairs of relationships (⟨R, R′ ⟩) and minimize their variance. The sample number we use is 500K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = len(O)\n",
    "num_samples = 500000\n",
    "\n",
    "from numpy.random import randint\n",
    "\n",
    "def sample_R(num_samples=500000)\n",
    "    R_rand = lambda O: Relationship(randint(N), randint(N), randint(K))\n",
    "    R_pairs = []\n",
    "    for n in range(num_samples):\n",
    "        R1 = R_rand(O)\n",
    "        R2 = R_rand(O)\n",
    "        R_pairs.append((R1, R2))\n",
    "    return R_pairs\n",
    "\n",
    "\n",
    "R_pairs = sample_R(O, num_samples)\n",
    "\n",
    "def K_fun(R_pairs, W, B, O, T)\n",
    "    D = []\n",
    "    for R1, R2 in R_pairs:\n",
    "        d = dist(R1, R2, W, B, O, T)\n",
    "        D.append(d)\n",
    "    return np.var(D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Likelihood of a Relationship\n",
    "\n",
    "![5](eqs/5.png)\n",
    "\n",
    "\n",
    "The output of our projection function should ideally indicate the likelihood of a visual relationship. For example, our model should not assign a high likelihood score to a relationship like ⟨dog - drive - car⟩, which is unlikely to occur. We model this by enforcing that if R occurs more frequently than R′ in our training data, then it should have a higher likelihood of occurring again. \n",
    "\n",
    "Minimizing this objective enforces that a relationship with a lower likelihood of occurring has a lower f () score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def L(R_pairs, W, B)\n",
    "    val = 0.0\n",
    "    for R1, R2 in R_pairs:\n",
    "        val += max(f(*R1.r, W, B) - f(*R2.r, W, B) + 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![6](eqs/6.png)\n",
    "\n",
    "Visual appearance module (V ()) and the language module (f ()). They are combined to maximize the rank of the ground truth relationship R with bounding boxes O1 and O2 using the following rank loss function C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def C(Z, S, W, B):\n",
    "    Rs = [R for R_pair in R_pairs for R in R_pair]\n",
    "    cs = []\n",
    "    \n",
    "    for R1 in Rs:\n",
    "        vis  = V(*R1.r, Z, S)\n",
    "        lang = f(*R1.r, W, B)\n",
    "        diff_R = lambda R1, R2: ((R1.i != R2.i) or (R1.j != R2.j)) and (R2.k != R2.k)\n",
    "        \n",
    "        c = max(V(*R2.r, Z, S) * f(*R2.r, W, B) for R2 in Rs if diff_R(R1, R2))\n",
    "        cs.append(max(c, 0))\n",
    "        \n",
    "    return sum(cs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![7](eqs/7.png)\n",
    "\n",
    "\n",
    "We use a ranking loss function to make it more likely for our model to choose the correct relationship. Given the large number of possible relationships, we find that 308 a classification loss performs worse. Therefore, our final objective function combines Eq 6 with Eqs 4 and 5 as Eq 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lamb1 = 0.05\n",
    "lamb2 = 0.001\n",
    "\n",
    "min_{Z,S,W,B} ( loss )\n",
    "\n",
    "loss = C(Z, S, W, B) + (lamb1 * K_fun(R_pairs, W, B, O, T)) + (lamb2 * L(R_pairs, W, B))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![8](eqs/8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = gensim.models.Word2Vec.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)\n",
    "word2vec = lambda t: M[t]\n",
    "\n",
    "# Visual appearence module\n",
    "# ---------------\n",
    "\n",
    "O = # TODO: object probabilities: get final layer vector of \"probabilities\" from VGG-16 standard\n",
    "R = # TODO: get final layer of relationship CNN (use tensorflow . . .)\n",
    "def V(i, j, k, Z, S, O, R):\n",
    "    P_i = O[i]\n",
    "    P_j = O[j]\n",
    "    P_k = np.dot(Z[k].T, R[k]) + S[k]\n",
    "    return P_i * P_j * P_k\n",
    "\n",
    "# Language module\n",
    "# ===============\n",
    "\n",
    "T = # TODO: T['word'] = index\n",
    "\n",
    "def F(i, j, W, B, T):\n",
    "    \"\"\"\n",
    "    Project relationship `R = <i,j>` to K-dim relationship space.\n",
    "    \"\"\"\n",
    "    w2v = np.concatenate(word2vec(T[i]), word2vec(T[j]))\n",
    "    return np.dot(W.T, w2v) + B\n",
    "\n",
    "def f(i, j, k, W, B, T):\n",
    "    \"\"\"\n",
    "    Project relationship `R = <i,j>` to scalar space.\n",
    "    \"\"\"\n",
    "    w2v = np.concatenate(word2vec(T[i]), word2vec(T[j]))\n",
    "    return np.dot(W[k].T, w2v) + B[k]\n",
    "\n",
    "# Training projection function\n",
    "# ----------------------------\n",
    "\n",
    "class Relationship:\n",
    "    def __init__(i, j, k):\n",
    "        self.r = (i,j,k)\n",
    "\n",
    "def dist(R1, R2, W, B, O, T):\n",
    "    d_rel = f(*R1.r, W, B, T) - f(*R2.r, W, B, T) \n",
    "    d_obj = M.similarity(M[R1.i], M[R1.j]) + \\\n",
    "            m.similarity(M[R2.i], M[R2.j])\n",
    "    return (d_rel ** 2) / d_obj\n",
    "\n",
    "N = len(O)\n",
    "num_samples = 500000\n",
    "\n",
    "from numpy.random import randint\n",
    "\n",
    "def sample_R(num_samples=500000)\n",
    "    R_rand = lambda O: Relationship(randint(N), randint(N), randint(K))\n",
    "    R_pairs = []\n",
    "    for n in range(num_samples):\n",
    "        R1 = R_rand(O)\n",
    "        R2 = R_rand(O)\n",
    "        R_pairs.append((R1, R2))\n",
    "    return R_pairs\n",
    "\n",
    "\n",
    "R_pairs = sample_R(O, num_samples)\n",
    "\n",
    "def K_fun(R_pairs, W, B, O, T)\n",
    "    D = []\n",
    "    for R1, R2 in R_pairs:\n",
    "        d = dist(R1, R2, W, B, O, T)\n",
    "        D.append(d)\n",
    "    return np.var(D)\n",
    "\n",
    "# Likelihood of a relationship\n",
    "# ----------------------------\n",
    "\n",
    "def L(R_pairs, W, B)\n",
    "    val = 0.0\n",
    "    for R1, R2 in R_pairs:\n",
    "        val += max(f(*R1.r, W, B) - f(*R2.r, W, B) + 1, 0)\n",
    "        \n",
    "# Rank loss function\n",
    "# ------------------\n",
    "\n",
    "def C(Z, S, W, B):\n",
    "    Rs = [R for R_pair in R_pairs for R in R_pair]\n",
    "    cs = []\n",
    "    \n",
    "    for R1 in Rs:\n",
    "        vis  = V(*R1.r, Z, S)\n",
    "        lang = f(*R1.r, W, B)\n",
    "        diff_R = lambda R1, R2: ((R1.i != R2.i) or (R1.j != R2.j)) and (R2.k != R2.k)\n",
    "        \n",
    "        c = max(V(*R2.r, Z, S) * f(*R2.r, W, B) for R2 in Rs if diff_R(R1, R2))\n",
    "        cs.append(max(c, 0))\n",
    "        \n",
    "    return sum(cs)\n",
    "\n",
    "\n",
    "# Final objective function\n",
    "# ------------------------\n",
    "\n",
    "lamb1 = 0.05\n",
    "lamb2 = 0.001\n",
    "\n",
    "min_{Z,S,W,B} ( loss )\n",
    "\n",
    "loss = C(Z, S, W, B) + (lamb1 * K_fun(R_pairs, W, B, O, T)) + (lamb2 * L(R_pairs, W, B))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = gensim.models.Word2Vec.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)\n",
    "word2vec = lambda t: M[t]\n",
    "\n",
    "from numpy.random import randint\n",
    "\n",
    "\n",
    "class Model:\n",
    "    \n",
    "    def __init__(self, TODO):\n",
    "        self.T   # TODO: T['word'] = word2vec index   (maybe do reverse also?)\n",
    "        self. \n",
    "        self.W\n",
    "        self.B\n",
    "        self.Z\n",
    "        self.S\n",
    "        self.w2v    # word2vec model\n",
    "        self.N = 100\n",
    "        self.K = 70\n",
    "        self.num_samples = 500000\n",
    "        self.lamb1 = 0.05\n",
    "        self.lamb2 = 0.001\n",
    "        self.batch_size = # TODO\n",
    "\n",
    "\n",
    "    # Visual appearence module\n",
    "    # ------------------------\n",
    "\n",
    "    def V(self, i, j, k, P_O1, P_O2, P_R):\n",
    "        P_O = # TODO: object probabilities: get final layer vector of \"probabilities\" from VGG-16 standard\n",
    "        P_R = # TODO: get final layer of relationship CNN (use tensorflow . . .)\n",
    "        \n",
    "        P_i = P_O1[i]\n",
    "        P_j = P_O2[j]\n",
    "        P_k = np.dot(self.Z[k].T, P_R[k]) + self.S[k]\n",
    "        return P_i * P_j * P_k\n",
    "    \n",
    "    def Vs(self, i, j, img_idx):\n",
    "        \"\"\"\n",
    "        Get 70-vector for all relationships for a given i,j.\n",
    "        \n",
    "        \"\"\"\n",
    "        P_i = self.P_O1[img_idx, i]\n",
    "        P_j = self.P_O2[img_idx, j]\n",
    "        P_r = self.P_R[img_idx, :]\n",
    "        P = np.dot(self.Z.T, P_r) + self.S\n",
    "        return P\n",
    "    \n",
    "    def V_all(self, img_ids, scene_graphs):\n",
    "        \"\"\"\n",
    "        Compute V for a list, with an arbitrary sized set of relation triplets for each.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "#         if len(img_ids) != len(img_Rs) != len(img_FRs):\n",
    "#             print 'Error: number of relationships != number of images'; return\n",
    "        \n",
    "        \n",
    "        # TODO: select only specific objects/relationships/scene graphs\n",
    "        objss = [scene_graph.objects for scene_graph in scene_graphs]\n",
    "        relss = [scene_graph.relationships for scene_graph in scene_graphs]\n",
    "        obj_coords = [[(obj.x, obj.y, obj.w, obj.h) for obj in objs] for objs in objss]\n",
    "        rel_coords = [[(rel.x, rel.y, rel.w, rel.h) for rel in rels] for rel in relss]\n",
    "        \n",
    "        \n",
    "\n",
    "        self.P_O = self.run_images(img_ids, obj_coords)\n",
    "        self.P_R = self.run_images(img_ids, rel_coords)\n",
    "\n",
    "        \n",
    "        \n",
    "        v_batch = {}    \n",
    "        for img_idx, scene_graph in enumerate(scene_graphs):\n",
    "            img_id = scene_graph.image.id  ## TODO: will this work?\n",
    "            P_o1 = self.P_O[img_idx, :]\n",
    "            P_o2 = self.P_O[img_idx, :]\n",
    "            P_r  = self.P_R[img_idx, :]\n",
    "            v_batch[img_id] = {R: self.V(*R, P_O1, P_O2, P_R) for R in img_Rs[img_idx]}\n",
    "            \n",
    "            \n",
    "#             ks = [k for i,j,k in img_Rs]\n",
    "#             v = {(i,j): self.Vs(i, j, P_O1, P_O2, P_R)[ks] for i,j,k in img_Rs[img_idx]}\n",
    "#             v_batch[img_id] = v\n",
    "\n",
    "                \n",
    "        return v_batch\n",
    "    \n",
    "    \n",
    "    def run_images(img_ids, coords):\n",
    "        \"\"\"\n",
    "        Load images, run cnn on each list of crop coords for each.\n",
    "        \n",
    "        \"\"\"\n",
    "        for img_id in img_ids:\n",
    "    \n",
    "    \n",
    "    def get_R(self, rel):\n",
    "        \"\"\"\n",
    "        TODO\n",
    "        ====\n",
    "        - have this turn a vg Relationship into a triplet (i,j,k)\n",
    "        - have a `self.dictionary` \n",
    "        \n",
    "        \"\"\"\n",
    "    \n",
    "    def get_cnn_prob(self, cnn, img_ids, layer='prob'):\n",
    "        ims = self.TODO_load_images(img_ids)\n",
    "        \n",
    "        cnn.feed({'data':ims})\n",
    "        cnn.run()\n",
    "        prob = cnn.get_layer_TODO('prob')\n",
    "                \n",
    "        \n",
    "                \n",
    "            \n",
    "            \n",
    "    \n",
    "\n",
    "    # Language module\n",
    "    # ===============\n",
    "\n",
    "    def F(self, i, j):\n",
    "        \"\"\"\n",
    "        Project relationship `R = <i,j>` to K-dim relationship space.\n",
    "        \"\"\"\n",
    "        word2vec = np.concatenate(self.w2v[self.T[i]], self.w2v[self.T[j]])\n",
    "        return np.dot(self.W.T, word2vec) + self.B\n",
    "\n",
    "    def f(self, i, j, k):\n",
    "        \"\"\"\n",
    "        Project relationship `R = <i,j>` to scalar space.\n",
    "        \"\"\"\n",
    "        word2vec = np.concatenate(self.w2v[self.T[i]], self.w2v[self.T[j]])\n",
    "        return np.dot(self.W[k].T, word2vec) + self.B[k]\n",
    "\n",
    "    # Training projection function\n",
    "    # ----------------------------\n",
    "\n",
    "    def dist(self, R1, R2):\n",
    "        \"\"\"\n",
    "        Distance between two predicate triplets.\n",
    "        \n",
    "        \"\"\"\n",
    "        d_rel = self.f(*R1.r) - f(*R2.r) \n",
    "        d_obj = self.M.similarity(self.M[R1[0]], self.M[R1[1]]) + \\\n",
    "                self.M.similarity(self.M[R2[0]], self.M[R2[1]])\n",
    "        return (d_rel ** 2) / d_obj\n",
    "\n",
    "    def sample_R(self):\n",
    "        \"\"\"\n",
    "        Draw a number of random (i,j,k) indices: 2 objects and 1 relationship\n",
    "        \n",
    "        \"\"\"\n",
    "        R_rand = lambda: (randint(self.N), randint(self.N), randint(self.K))\n",
    "        R_pairs = [(R_rand(), R_rand()) for n in range(self.num_samples)]\n",
    "        return R_pairs\n",
    "\n",
    "    def K_fun(self)\n",
    "        \"\"\"\n",
    "        Eq (4): randomly sample relationship pairs and minimize variance.\n",
    "        \n",
    "        \"\"\"\n",
    "        R_samples = self.sample_R()\n",
    "\n",
    "        D = []\n",
    "        for R1, R2 in R_samples:\n",
    "            d = dist(R1, R2)\n",
    "            D.append(d)\n",
    "        return np.var(D)\n",
    "\n",
    "    def L(self, Rs):\n",
    "        \"\"\"\n",
    "        Likelihood of a sampled relatinoships\n",
    "        \n",
    "        \"\"\"\n",
    "        val = 0.0\n",
    "        for R1 in Rs:\n",
    "            for R2 in Rs:\n",
    "                val += max(self.f(*R1) - self.f(*R2) + 1, 0)\n",
    "\n",
    "    def C(self, Rs, TODO_IMG):\n",
    "        \"\"\"\n",
    "        Rank loss function\n",
    "        \n",
    "        Rs : list of relationships for training data\n",
    "        \n",
    "        \"\"\"\n",
    "        cs = []\n",
    "        for R1 in Rs:\n",
    "            c = max(V(*R2) * f(*R2) for R2 in Rs if  \\\n",
    "                    (R2[2] != R2[2]) and ((R1[0] != R2[0]) or (R1[1] != R2[1])))\n",
    "            c = max(1 + V(*R1) * f(*R1) * c, 0)\n",
    "            cs.append(c)\n",
    "        return sum(cs)\n",
    "\n",
    "    def objective(self, Rs, TODO_IMG):\n",
    "        \"\"\"\n",
    "        Final objective function.\n",
    "        \n",
    "        \"\"\"\n",
    "        loss = self.C(Rs, TODO_IMG) +  \\\n",
    "               (self.lamb1 * self.K_fun() +  \\\n",
    "               (self.lamb2 * L(R_pairs, W, B))\n",
    "        return loss\n",
    "                \n",
    "    def SGD(self, TODO):\n",
    "        \"\"\"\n",
    "        Perform SGD over eqs 5 (L) 6 (C)\n",
    "        \"\"\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
