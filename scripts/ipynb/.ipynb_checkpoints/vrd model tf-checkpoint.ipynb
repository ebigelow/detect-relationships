{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import loadmat, mat_to_tf\n",
    "from model_tf import Model\n",
    "\n",
    "import tensorflow as tf\n",
    "from utils import load_sg_batcher\n",
    "# from vgg16 import CustomVgg16\n",
    "import numpy as np\n",
    "\n",
    "# tf.app.flags.DEFINE_float('gpu_mem_fraction', 0.9, '')\n",
    "\n",
    "epochs     = 20\n",
    "batch_size = 10\n",
    "\n",
    "obj_mat   = 'data/vrd/objectListN.mat'\n",
    "rel_mat   = 'data/vrd/predicate.mat'\n",
    "train_mat = 'data/vrd/annotation_train.mat'\n",
    "test_mat  = 'data/vrd/annotation_test.mat'\n",
    "\n",
    "w2v_file  = 'data/vrd/w2v.npy'\n",
    "obj_npy   = 'data/vrd/obj_probs.npy'\n",
    "rel_npy   = 'data/vrd/rel_feats.npy'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Load data\n",
    "\n",
    "obj_dict = {r:i for i,r in enumerate(loadmat(FLAGS.obj_mat)['objectListN'])}\n",
    "rel_dict = {r:i for i,r in enumerate(loadmat(FLAGS.rel_mat)['predicate'])}\n",
    "\n",
    "word2idx = {'obj':obj_dict, 'rel':rel_dict}\n",
    "w2v = np.load(FLAGS.w2v_file)      # TODO: make sure this is in (dict -> matrix) form\n",
    "\n",
    "obj_probs = np.load(FLAGS.obj_npy).item()\n",
    "rel_feats = np.load(FLAGS.rel_npy).item()\n",
    "\n",
    "train_mat = loadmat(FLAGS.train_mat)['annotation_train']\n",
    "test_mat  = loadmat(FLAGS.test_mat)['annotation_test']\n",
    "# D = mat_to_triplets(mat, word2idx)\n",
    "train_data = mat_to_tf(train_mat, word2idx, obj_probs, rel_feats, FLAGS.batch_size)\n",
    "test_data  = mat_to_tf(test_mat,  word2idx, obj_probs, rel_feats, FLAGS.batch_size)\n",
    "\n",
    "R_full = (np.concat(train_data[0]),\n",
    "          np.concat(train_data[1]),\n",
    "          np.concat(train_data[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Run model\n",
    "\n",
    "model = Model(w2v, learning_rate=0.1, lamb1=5e-2, max_iters=50, noise=1.0)\n",
    "cost = model.loss(D, R_full)\n",
    "#train_op = tf.train.AdamOptimizer(FLAGS.learning_rate).minimize(cost)\n",
    "train_op = tf.train.GradientDescentOptimizer(FLAGS.learning_rate).minimize(cost)\n",
    "ground_truth = self.get_ground_truth()\n",
    "accuracy = model.get_accuracy(ground_truth)\n",
    "\n",
    "batch_to_feed = lambda I, J, K, op, rf, R_full: { \\\n",
    "    ground_truth['I']: I,\n",
    "    ground_truth['J']: J,\n",
    "    ground_truth['K']: K,\n",
    "    ground_truth['obj_probs']: op,\n",
    "    ground_truth['rel_feats']: rf,\n",
    "    ground_truth['R_full']: R_full\n",
    "}\n",
    "\n",
    "best_acc = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: CPU ONLY\n",
    "# with session_init() as sess:\n",
    "with tf.Session() as sess:\n",
    "    merged = tf.merge_all_summaries()\n",
    "    train_writer = tf.train.SummaryWriter(FLAGS.summaries_dir + '/train', sess.graph)\n",
    "    test_writer = tf.train.SummaryWriter(FLAGS.summaries_dir + '/test')\n",
    "    tf.initialize_all_variables().run()\n",
    "\n",
    "    for e in range(FLAGS.epochs):\n",
    "        print 'Beginning epoch {}'.format(e)\n",
    "\n",
    "        for db, data_batch in enumerate(train_data):\n",
    "            if db % 100 == 0:\n",
    "                # if db % 100000 == 0: # TODO\n",
    "                #     summary, acc = sess.run([merged, accuracy], feed_dict=feed_dict(False))\n",
    "                #     test_writer.add_summary(summary, i)\n",
    "                #     accs = []\n",
    "                #     for test_batch in test_data:\n",
    "                #         feed_test = batch_to_feed(*test_batch)\n",
    "                #         accs.append(sess.run(accuracy, feed_dict=feed_test))\n",
    "                #     acc = np.mean(accs)\n",
    "                #     print ' => epoch {} batch {}  |  Acurracy: {}'.format(e, db, acc)\n",
    "                #     if acc > best_acc:\n",
    "                #         model.save_npy(sess, file_path=FLAGS.save_weights + '_{}-{}.npy'.format(e,db))\n",
    "\n",
    "                feed_train = batch_to_feed(*data_batch)\n",
    "\n",
    "                # Record train set summaries, and train\n",
    "                run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "                run_metadata = tf.RunMetadata()\n",
    "                summary, _ = sess.run([merged, train_op], feed_dict=feed_train,\n",
    "                                      options=run_options, run_metadata=run_metadata)\n",
    "                # TODO look up docs ...\n",
    "                train_writer.add_run_metadata(run_metadata, 'epoch {}, batch {}'.format(e, batch))\n",
    "                print('Adding run metadata for', i)\n",
    "            else:\n",
    "                # Record Train\n",
    "                summary, _ = sess.run([merged, train_step], feed_dict=feed_test)\n",
    "\n",
    "            train_writer.add_summary(summary, i)\n",
    "\n",
    "\n",
    "    train_writer.close()\n",
    "    test_writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
